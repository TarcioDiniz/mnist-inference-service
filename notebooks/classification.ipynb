{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-27T11:58:36.381741300Z",
     "start_time": "2026-01-27T11:58:33.241699Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:58:47.136256600Z",
     "start_time": "2026-01-27T11:58:41.327303900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"../weights\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"../weights\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ],
   "id": "31dcc22cc1faf74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:58:50.487286900Z",
     "start_time": "2026-01-27T11:58:50.467600900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "X, y = next(iter(train_loader))\n",
    "\n",
    "for X, y in test_loader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ],
   "id": "eba012576d79ab38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:58:52.455838700Z",
     "start_time": "2026-01-27T11:58:52.359320900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_image_seaborn(img, label):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(img.squeeze(), cmap=\"gray\", cbar=False, xticklabels=False, yticklabels=False)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_image_seaborn(X[0], y[0].item())"
   ],
   "id": "da315ee18e682610",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:58:55.229267600Z",
     "start_time": "2026-01-27T11:58:55.158728500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get cpu, gpu device for training.\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Version (torch): {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Dispositivo: {torch.cuda.get_device_name(0)}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ],
   "id": "1f1df2a51ea4011",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.10.0+cu130\n",
      "CUDA Version (torch): 13.0\n",
      "Dispositivo: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Using cuda device\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:58:56.801845600Z",
     "start_time": "2026-01-27T11:58:56.650911500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "id": "f22ad8a707aa9843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:58:59.051772100Z",
     "start_time": "2026-01-27T11:58:58.845869700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = X[:1].to(device)\n",
    "model(x)"
   ],
   "id": "4d130a82a75fba00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0381, -0.0303,  0.0414, -0.0148,  0.0076, -0.0346,  0.0250, -0.0070,\n",
       "          0.0036, -0.0083]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:59:01.387596400Z",
     "start_time": "2026-01-27T11:59:01.306911100Z"
    }
   },
   "cell_type": "code",
   "source": "list(model.linear_relu_stack[0].parameters())",
   "id": "d899ff3690f93caf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0112,  0.0168, -0.0065,  ...,  0.0317, -0.0240, -0.0327],\n",
       "         [ 0.0295,  0.0218,  0.0159,  ..., -0.0255, -0.0154, -0.0292],\n",
       "         [-0.0090,  0.0280,  0.0275,  ...,  0.0354, -0.0352, -0.0290],\n",
       "         ...,\n",
       "         [ 0.0029, -0.0043, -0.0045,  ...,  0.0030,  0.0158,  0.0322],\n",
       "         [-0.0029,  0.0036, -0.0248,  ..., -0.0282, -0.0082, -0.0136],\n",
       "         [ 0.0159, -0.0225, -0.0078,  ...,  0.0018, -0.0055, -0.0243]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0199, -0.0213, -0.0356,  0.0312, -0.0241, -0.0343,  0.0287, -0.0092,\n",
       "          0.0340,  0.0185,  0.0091, -0.0213, -0.0160, -0.0217, -0.0098,  0.0065,\n",
       "          0.0116, -0.0086,  0.0190,  0.0149, -0.0192,  0.0324, -0.0251,  0.0239,\n",
       "         -0.0112,  0.0129, -0.0164,  0.0265,  0.0190, -0.0173,  0.0027, -0.0183,\n",
       "          0.0117, -0.0277,  0.0096,  0.0071,  0.0315, -0.0223, -0.0174,  0.0128,\n",
       "         -0.0192,  0.0186, -0.0033,  0.0044, -0.0323, -0.0137, -0.0289, -0.0246,\n",
       "          0.0287, -0.0336, -0.0178,  0.0325,  0.0028,  0.0119,  0.0179, -0.0351,\n",
       "         -0.0204,  0.0251, -0.0005,  0.0207, -0.0280, -0.0329, -0.0051,  0.0305,\n",
       "          0.0283,  0.0304,  0.0070, -0.0190,  0.0336, -0.0284, -0.0323, -0.0157,\n",
       "          0.0143, -0.0025, -0.0045, -0.0235, -0.0256, -0.0209, -0.0309,  0.0165,\n",
       "         -0.0181, -0.0098,  0.0039,  0.0079,  0.0095, -0.0351, -0.0239, -0.0237,\n",
       "          0.0020,  0.0128,  0.0262, -0.0119, -0.0255,  0.0249,  0.0064, -0.0041,\n",
       "          0.0234, -0.0214, -0.0253,  0.0140,  0.0133,  0.0104,  0.0292,  0.0144,\n",
       "         -0.0168, -0.0124, -0.0124,  0.0255,  0.0156, -0.0060, -0.0058,  0.0034,\n",
       "         -0.0010, -0.0293,  0.0298,  0.0119,  0.0051, -0.0123, -0.0050, -0.0021,\n",
       "         -0.0052, -0.0254,  0.0251,  0.0205, -0.0124,  0.0352, -0.0154,  0.0143,\n",
       "          0.0044,  0.0183, -0.0072, -0.0046,  0.0037, -0.0049,  0.0032, -0.0042,\n",
       "          0.0070, -0.0096, -0.0021, -0.0294, -0.0280,  0.0126, -0.0174,  0.0282,\n",
       "         -0.0003,  0.0255,  0.0259,  0.0142,  0.0260, -0.0190, -0.0178, -0.0008,\n",
       "         -0.0061, -0.0020,  0.0033, -0.0355,  0.0342,  0.0200,  0.0071,  0.0273,\n",
       "          0.0266, -0.0350,  0.0167,  0.0311, -0.0296, -0.0272,  0.0195, -0.0008,\n",
       "          0.0305, -0.0153,  0.0295,  0.0002,  0.0296,  0.0036,  0.0340, -0.0229,\n",
       "         -0.0152, -0.0346,  0.0280, -0.0338, -0.0197,  0.0254, -0.0251, -0.0199,\n",
       "          0.0178,  0.0186,  0.0012,  0.0195, -0.0331,  0.0264,  0.0144,  0.0269,\n",
       "          0.0187,  0.0038, -0.0127, -0.0288,  0.0322, -0.0296, -0.0040,  0.0245,\n",
       "          0.0224, -0.0229, -0.0282,  0.0040,  0.0171,  0.0028,  0.0163,  0.0227,\n",
       "          0.0221,  0.0155, -0.0035,  0.0055,  0.0036,  0.0189, -0.0131, -0.0121,\n",
       "         -0.0077,  0.0242,  0.0304, -0.0147,  0.0090, -0.0222, -0.0034, -0.0136,\n",
       "         -0.0327,  0.0172,  0.0159,  0.0098, -0.0228,  0.0139,  0.0204,  0.0125,\n",
       "         -0.0338,  0.0276, -0.0339,  0.0244,  0.0225,  0.0096, -0.0037,  0.0211,\n",
       "         -0.0346, -0.0186, -0.0084, -0.0046, -0.0313, -0.0054, -0.0318, -0.0317,\n",
       "          0.0282, -0.0306, -0.0061,  0.0073, -0.0285, -0.0262,  0.0013,  0.0163,\n",
       "         -0.0012, -0.0090, -0.0264,  0.0212, -0.0353, -0.0318,  0.0059,  0.0330,\n",
       "          0.0121, -0.0259,  0.0026, -0.0164,  0.0263,  0.0314, -0.0334, -0.0265,\n",
       "         -0.0346, -0.0280, -0.0022,  0.0289, -0.0283, -0.0064,  0.0334, -0.0078,\n",
       "          0.0281,  0.0080, -0.0009, -0.0313, -0.0205,  0.0277, -0.0285,  0.0028,\n",
       "         -0.0075,  0.0032,  0.0083, -0.0130,  0.0012,  0.0097,  0.0101,  0.0144,\n",
       "          0.0328, -0.0080,  0.0209,  0.0009, -0.0028,  0.0284, -0.0107, -0.0272,\n",
       "          0.0289,  0.0283, -0.0026, -0.0127,  0.0288,  0.0040, -0.0124,  0.0179,\n",
       "          0.0152,  0.0174, -0.0035, -0.0269, -0.0109,  0.0194, -0.0239, -0.0215,\n",
       "         -0.0294, -0.0213, -0.0174, -0.0039,  0.0146,  0.0148,  0.0306, -0.0213,\n",
       "          0.0188, -0.0245,  0.0295, -0.0106,  0.0186, -0.0136,  0.0032,  0.0147,\n",
       "         -0.0205,  0.0330,  0.0090, -0.0300, -0.0192, -0.0055,  0.0164, -0.0018,\n",
       "         -0.0105, -0.0035, -0.0354, -0.0200, -0.0060, -0.0019,  0.0083, -0.0115,\n",
       "          0.0005,  0.0101, -0.0010,  0.0140,  0.0033, -0.0291,  0.0171,  0.0027,\n",
       "         -0.0032, -0.0054, -0.0309,  0.0020, -0.0308,  0.0030, -0.0004, -0.0161,\n",
       "          0.0079,  0.0075,  0.0133,  0.0151, -0.0337,  0.0347,  0.0254,  0.0294,\n",
       "         -0.0073, -0.0284,  0.0085,  0.0298,  0.0085, -0.0091,  0.0318, -0.0321,\n",
       "         -0.0022,  0.0121, -0.0100,  0.0239, -0.0154,  0.0273, -0.0046,  0.0236,\n",
       "         -0.0172, -0.0187, -0.0183, -0.0333,  0.0347,  0.0247, -0.0251,  0.0320,\n",
       "         -0.0199,  0.0226, -0.0278, -0.0261,  0.0084,  0.0326, -0.0052, -0.0015,\n",
       "          0.0227,  0.0092, -0.0100, -0.0133,  0.0274, -0.0056,  0.0230,  0.0042,\n",
       "          0.0182, -0.0131,  0.0211,  0.0058,  0.0064,  0.0090, -0.0191,  0.0012,\n",
       "         -0.0223, -0.0118, -0.0080, -0.0293, -0.0092, -0.0306,  0.0259, -0.0351,\n",
       "          0.0157, -0.0097,  0.0292,  0.0346, -0.0307,  0.0012, -0.0246, -0.0306,\n",
       "         -0.0295,  0.0164,  0.0040, -0.0349, -0.0069,  0.0172, -0.0269, -0.0027,\n",
       "          0.0214,  0.0106,  0.0093, -0.0244, -0.0039, -0.0113,  0.0050, -0.0134,\n",
       "         -0.0246, -0.0230, -0.0084, -0.0248, -0.0216, -0.0349,  0.0052,  0.0021,\n",
       "         -0.0285, -0.0230, -0.0175, -0.0249,  0.0168,  0.0151,  0.0252,  0.0081,\n",
       "         -0.0291,  0.0165, -0.0275, -0.0077,  0.0131,  0.0254, -0.0266,  0.0321,\n",
       "          0.0032, -0.0243, -0.0162,  0.0143, -0.0280, -0.0311, -0.0047,  0.0165,\n",
       "          0.0346,  0.0301, -0.0134, -0.0336, -0.0149,  0.0025, -0.0159, -0.0054,\n",
       "          0.0293, -0.0084,  0.0168, -0.0059,  0.0344,  0.0290, -0.0040, -0.0250,\n",
       "          0.0040,  0.0250,  0.0012, -0.0315,  0.0304, -0.0341, -0.0284, -0.0258],\n",
       "        device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:59:03.884139500Z",
     "start_time": "2026-01-27T11:59:03.874112700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ],
   "id": "6f8b0477841b56ac",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:59:05.578002300Z",
     "start_time": "2026-01-27T11:59:05.571696400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "id": "734f1fa170acb026",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:59:07.842628500Z",
     "start_time": "2026-01-27T11:59:07.832735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ],
   "id": "63ad1cd5b4f81af8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T11:59:46.858183300Z",
     "start_time": "2026-01-27T11:59:09.344121900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "start = time.time()\n",
    "epochs = 5\n",
    "test(test_loader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done in \", time.time() - start, \"seconds.\")"
   ],
   "id": "eb7cf9030e0f8073",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 10.2%, Avg loss: 2.303416 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306710  [    0/60000]\n",
      "loss: 2.303918  [ 6400/60000]\n",
      "loss: 2.294204  [12800/60000]\n",
      "loss: 2.295949  [19200/60000]\n",
      "loss: 2.286771  [25600/60000]\n",
      "loss: 2.280542  [32000/60000]\n",
      "loss: 2.270997  [38400/60000]\n",
      "loss: 2.280334  [44800/60000]\n",
      "loss: 2.265150  [51200/60000]\n",
      "loss: 2.263386  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 2.258849 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.260542  [    0/60000]\n",
      "loss: 2.254341  [ 6400/60000]\n",
      "loss: 2.257848  [12800/60000]\n",
      "loss: 2.235020  [19200/60000]\n",
      "loss: 2.238485  [25600/60000]\n",
      "loss: 2.231320  [32000/60000]\n",
      "loss: 2.215099  [38400/60000]\n",
      "loss: 2.236560  [44800/60000]\n",
      "loss: 2.205826  [51200/60000]\n",
      "loss: 2.203989  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 2.196244 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.196597  [    0/60000]\n",
      "loss: 2.183880  [ 6400/60000]\n",
      "loss: 2.203177  [12800/60000]\n",
      "loss: 2.146189  [19200/60000]\n",
      "loss: 2.162142  [25600/60000]\n",
      "loss: 2.151602  [32000/60000]\n",
      "loss: 2.123774  [38400/60000]\n",
      "loss: 2.162005  [44800/60000]\n",
      "loss: 2.106910  [51200/60000]\n",
      "loss: 2.103539  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 2.089181 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.088888  [    0/60000]\n",
      "loss: 2.063245  [ 6400/60000]\n",
      "loss: 2.105905  [12800/60000]\n",
      "loss: 1.997467  [19200/60000]\n",
      "loss: 2.027429  [25600/60000]\n",
      "loss: 2.010256  [32000/60000]\n",
      "loss: 1.964804  [38400/60000]\n",
      "loss: 2.028502  [44800/60000]\n",
      "loss: 1.936017  [51200/60000]\n",
      "loss: 1.925951  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.901804 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.903219  [    0/60000]\n",
      "loss: 1.856443  [ 6400/60000]\n",
      "loss: 1.930074  [12800/60000]\n",
      "loss: 1.754820  [19200/60000]\n",
      "loss: 1.792896  [25600/60000]\n",
      "loss: 1.767882  [32000/60000]\n",
      "loss: 1.706747  [38400/60000]\n",
      "loss: 1.804986  [44800/60000]\n",
      "loss: 1.669028  [51200/60000]\n",
      "loss: 1.647395  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 1.612056 \n",
      "\n",
      "Done in  37.5019211769104 seconds.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T12:12:19.424805Z",
     "start_time": "2026-01-27T12:02:02.563042200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "epochs = 95\n",
    "test(test_loader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done in \", time.time() - start, \"seconds.\")"
   ],
   "id": "a7004e54d538fc02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 1.612056 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.626458  [    0/60000]\n",
      "loss: 1.548995  [ 6400/60000]\n",
      "loss: 1.650334  [12800/60000]\n",
      "loss: 1.433250  [19200/60000]\n",
      "loss: 1.464676  [25600/60000]\n",
      "loss: 1.435431  [32000/60000]\n",
      "loss: 1.373410  [38400/60000]\n",
      "loss: 1.508059  [44800/60000]\n",
      "loss: 1.359896  [51200/60000]\n",
      "loss: 1.323620  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 1.285208 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.328705  [    0/60000]\n",
      "loss: 1.221953  [ 6400/60000]\n",
      "loss: 1.330881  [12800/60000]\n",
      "loss: 1.137837  [19200/60000]\n",
      "loss: 1.154189  [25600/60000]\n",
      "loss: 1.124412  [32000/60000]\n",
      "loss: 1.072817  [38400/60000]\n",
      "loss: 1.228875  [44800/60000]\n",
      "loss: 1.109973  [51200/60000]\n",
      "loss: 1.061962  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 1.026756 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.100508  [    0/60000]\n",
      "loss: 0.976993  [ 6400/60000]\n",
      "loss: 1.072992  [12800/60000]\n",
      "loss: 0.929627  [19200/60000]\n",
      "loss: 0.935854  [25600/60000]\n",
      "loss: 0.904252  [32000/60000]\n",
      "loss: 0.861771  [38400/60000]\n",
      "loss: 1.024163  [44800/60000]\n",
      "loss: 0.940446  [51200/60000]\n",
      "loss: 0.889404  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.853179 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.945643  [    0/60000]\n",
      "loss: 0.814842  [ 6400/60000]\n",
      "loss: 0.893749  [12800/60000]\n",
      "loss: 0.792497  [19200/60000]\n",
      "loss: 0.792880  [25600/60000]\n",
      "loss: 0.759993  [32000/60000]\n",
      "loss: 0.719918  [38400/60000]\n",
      "loss: 0.883416  [44800/60000]\n",
      "loss: 0.825178  [51200/60000]\n",
      "loss: 0.778830  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.736819 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.838235  [    0/60000]\n",
      "loss: 0.704312  [ 6400/60000]\n",
      "loss: 0.769558  [12800/60000]\n",
      "loss: 0.700377  [19200/60000]\n",
      "loss: 0.694869  [25600/60000]\n",
      "loss: 0.664068  [32000/60000]\n",
      "loss: 0.620225  [38400/60000]\n",
      "loss: 0.785909  [44800/60000]\n",
      "loss: 0.741922  [51200/60000]\n",
      "loss: 0.705088  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.655338 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.759477  [    0/60000]\n",
      "loss: 0.624217  [ 6400/60000]\n",
      "loss: 0.680619  [12800/60000]\n",
      "loss: 0.635980  [19200/60000]\n",
      "loss: 0.623963  [25600/60000]\n",
      "loss: 0.598496  [32000/60000]\n",
      "loss: 0.547009  [38400/60000]\n",
      "loss: 0.716852  [44800/60000]\n",
      "loss: 0.678608  [51200/60000]\n",
      "loss: 0.653576  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.595717 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.698596  [    0/60000]\n",
      "loss: 0.563592  [ 6400/60000]\n",
      "loss: 0.614668  [12800/60000]\n",
      "loss: 0.589250  [19200/60000]\n",
      "loss: 0.570201  [25600/60000]\n",
      "loss: 0.552466  [32000/60000]\n",
      "loss: 0.491425  [38400/60000]\n",
      "loss: 0.666510  [44800/60000]\n",
      "loss: 0.628915  [51200/60000]\n",
      "loss: 0.616382  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.550447 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.649739  [    0/60000]\n",
      "loss: 0.516189  [ 6400/60000]\n",
      "loss: 0.563860  [12800/60000]\n",
      "loss: 0.554165  [19200/60000]\n",
      "loss: 0.527988  [25600/60000]\n",
      "loss: 0.519185  [32000/60000]\n",
      "loss: 0.448133  [38400/60000]\n",
      "loss: 0.628836  [44800/60000]\n",
      "loss: 0.589147  [51200/60000]\n",
      "loss: 0.588639  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.514997 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.609267  [    0/60000]\n",
      "loss: 0.478325  [ 6400/60000]\n",
      "loss: 0.523587  [12800/60000]\n",
      "loss: 0.526980  [19200/60000]\n",
      "loss: 0.493857  [25600/60000]\n",
      "loss: 0.494390  [32000/60000]\n",
      "loss: 0.413696  [38400/60000]\n",
      "loss: 0.599764  [44800/60000]\n",
      "loss: 0.556903  [51200/60000]\n",
      "loss: 0.567347  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.486530 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.574826  [    0/60000]\n",
      "loss: 0.447633  [ 6400/60000]\n",
      "loss: 0.490754  [12800/60000]\n",
      "loss: 0.505385  [19200/60000]\n",
      "loss: 0.465642  [25600/60000]\n",
      "loss: 0.475368  [32000/60000]\n",
      "loss: 0.385816  [38400/60000]\n",
      "loss: 0.576540  [44800/60000]\n",
      "loss: 0.530477  [51200/60000]\n",
      "loss: 0.550549  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.463198 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.545059  [    0/60000]\n",
      "loss: 0.422500  [ 6400/60000]\n",
      "loss: 0.463292  [12800/60000]\n",
      "loss: 0.487786  [19200/60000]\n",
      "loss: 0.441932  [25600/60000]\n",
      "loss: 0.460361  [32000/60000]\n",
      "loss: 0.362787  [38400/60000]\n",
      "loss: 0.557527  [44800/60000]\n",
      "loss: 0.508510  [51200/60000]\n",
      "loss: 0.537034  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.443745 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.519027  [    0/60000]\n",
      "loss: 0.401754  [ 6400/60000]\n",
      "loss: 0.439807  [12800/60000]\n",
      "loss: 0.473143  [19200/60000]\n",
      "loss: 0.421721  [25600/60000]\n",
      "loss: 0.448196  [32000/60000]\n",
      "loss: 0.343492  [38400/60000]\n",
      "loss: 0.541560  [44800/60000]\n",
      "loss: 0.490008  [51200/60000]\n",
      "loss: 0.525821  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.427304 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.495954  [    0/60000]\n",
      "loss: 0.384463  [ 6400/60000]\n",
      "loss: 0.419386  [12800/60000]\n",
      "loss: 0.460700  [19200/60000]\n",
      "loss: 0.404281  [25600/60000]\n",
      "loss: 0.438069  [32000/60000]\n",
      "loss: 0.327133  [38400/60000]\n",
      "loss: 0.527821  [44800/60000]\n",
      "loss: 0.474177  [51200/60000]\n",
      "loss: 0.516346  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.413239 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.475345  [    0/60000]\n",
      "loss: 0.369944  [ 6400/60000]\n",
      "loss: 0.401359  [12800/60000]\n",
      "loss: 0.449983  [19200/60000]\n",
      "loss: 0.389091  [25600/60000]\n",
      "loss: 0.429371  [32000/60000]\n",
      "loss: 0.313045  [38400/60000]\n",
      "loss: 0.515837  [44800/60000]\n",
      "loss: 0.460503  [51200/60000]\n",
      "loss: 0.508197  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.401080 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.456826  [    0/60000]\n",
      "loss: 0.357670  [ 6400/60000]\n",
      "loss: 0.385240  [12800/60000]\n",
      "loss: 0.440650  [19200/60000]\n",
      "loss: 0.375702  [25600/60000]\n",
      "loss: 0.421748  [32000/60000]\n",
      "loss: 0.300789  [38400/60000]\n",
      "loss: 0.505185  [44800/60000]\n",
      "loss: 0.448560  [51200/60000]\n",
      "loss: 0.500993  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.390465 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.439993  [    0/60000]\n",
      "loss: 0.347211  [ 6400/60000]\n",
      "loss: 0.370669  [12800/60000]\n",
      "loss: 0.432426  [19200/60000]\n",
      "loss: 0.363823  [25600/60000]\n",
      "loss: 0.414931  [32000/60000]\n",
      "loss: 0.290034  [38400/60000]\n",
      "loss: 0.495678  [44800/60000]\n",
      "loss: 0.437991  [51200/60000]\n",
      "loss: 0.494596  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.381114 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.424630  [    0/60000]\n",
      "loss: 0.338269  [ 6400/60000]\n",
      "loss: 0.357404  [12800/60000]\n",
      "loss: 0.425142  [19200/60000]\n",
      "loss: 0.353210  [25600/60000]\n",
      "loss: 0.408728  [32000/60000]\n",
      "loss: 0.280494  [38400/60000]\n",
      "loss: 0.487071  [44800/60000]\n",
      "loss: 0.428517  [51200/60000]\n",
      "loss: 0.488814  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.372804 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.410531  [    0/60000]\n",
      "loss: 0.330584  [ 6400/60000]\n",
      "loss: 0.345247  [12800/60000]\n",
      "loss: 0.418629  [19200/60000]\n",
      "loss: 0.343665  [25600/60000]\n",
      "loss: 0.403009  [32000/60000]\n",
      "loss: 0.271956  [38400/60000]\n",
      "loss: 0.479227  [44800/60000]\n",
      "loss: 0.419952  [51200/60000]\n",
      "loss: 0.483520  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.365355 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.397513  [    0/60000]\n",
      "loss: 0.323929  [ 6400/60000]\n",
      "loss: 0.334050  [12800/60000]\n",
      "loss: 0.412703  [19200/60000]\n",
      "loss: 0.334989  [25600/60000]\n",
      "loss: 0.397703  [32000/60000]\n",
      "loss: 0.264254  [38400/60000]\n",
      "loss: 0.471998  [44800/60000]\n",
      "loss: 0.412135  [51200/60000]\n",
      "loss: 0.478652  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.358629 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.385471  [    0/60000]\n",
      "loss: 0.318127  [ 6400/60000]\n",
      "loss: 0.323711  [12800/60000]\n",
      "loss: 0.407357  [19200/60000]\n",
      "loss: 0.327048  [25600/60000]\n",
      "loss: 0.392676  [32000/60000]\n",
      "loss: 0.257299  [38400/60000]\n",
      "loss: 0.465329  [44800/60000]\n",
      "loss: 0.404966  [51200/60000]\n",
      "loss: 0.474121  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.352507 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.374278  [    0/60000]\n",
      "loss: 0.313037  [ 6400/60000]\n",
      "loss: 0.314092  [12800/60000]\n",
      "loss: 0.402471  [19200/60000]\n",
      "loss: 0.319737  [25600/60000]\n",
      "loss: 0.387898  [32000/60000]\n",
      "loss: 0.250982  [38400/60000]\n",
      "loss: 0.459166  [44800/60000]\n",
      "loss: 0.398306  [51200/60000]\n",
      "loss: 0.469837  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.346897 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.363838  [    0/60000]\n",
      "loss: 0.308530  [ 6400/60000]\n",
      "loss: 0.305163  [12800/60000]\n",
      "loss: 0.397935  [19200/60000]\n",
      "loss: 0.312932  [25600/60000]\n",
      "loss: 0.383350  [32000/60000]\n",
      "loss: 0.245220  [38400/60000]\n",
      "loss: 0.453418  [44800/60000]\n",
      "loss: 0.392028  [51200/60000]\n",
      "loss: 0.465814  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.341728 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.354056  [    0/60000]\n",
      "loss: 0.304549  [ 6400/60000]\n",
      "loss: 0.296850  [12800/60000]\n",
      "loss: 0.393746  [19200/60000]\n",
      "loss: 0.306569  [25600/60000]\n",
      "loss: 0.379024  [32000/60000]\n",
      "loss: 0.239948  [38400/60000]\n",
      "loss: 0.448022  [44800/60000]\n",
      "loss: 0.386058  [51200/60000]\n",
      "loss: 0.461998  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.336934 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.344821  [    0/60000]\n",
      "loss: 0.300992  [ 6400/60000]\n",
      "loss: 0.289095  [12800/60000]\n",
      "loss: 0.389856  [19200/60000]\n",
      "loss: 0.300590  [25600/60000]\n",
      "loss: 0.374909  [32000/60000]\n",
      "loss: 0.235096  [38400/60000]\n",
      "loss: 0.442978  [44800/60000]\n",
      "loss: 0.380328  [51200/60000]\n",
      "loss: 0.458334  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.332467 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.336123  [    0/60000]\n",
      "loss: 0.297821  [ 6400/60000]\n",
      "loss: 0.281831  [12800/60000]\n",
      "loss: 0.386208  [19200/60000]\n",
      "loss: 0.294970  [25600/60000]\n",
      "loss: 0.370993  [32000/60000]\n",
      "loss: 0.230650  [38400/60000]\n",
      "loss: 0.438226  [44800/60000]\n",
      "loss: 0.374848  [51200/60000]\n",
      "loss: 0.454812  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.328285 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.327920  [    0/60000]\n",
      "loss: 0.294923  [ 6400/60000]\n",
      "loss: 0.274995  [12800/60000]\n",
      "loss: 0.382765  [19200/60000]\n",
      "loss: 0.289665  [25600/60000]\n",
      "loss: 0.367256  [32000/60000]\n",
      "loss: 0.226563  [38400/60000]\n",
      "loss: 0.433762  [44800/60000]\n",
      "loss: 0.369639  [51200/60000]\n",
      "loss: 0.451367  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.324354 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.320106  [    0/60000]\n",
      "loss: 0.292226  [ 6400/60000]\n",
      "loss: 0.268563  [12800/60000]\n",
      "loss: 0.379527  [19200/60000]\n",
      "loss: 0.284624  [25600/60000]\n",
      "loss: 0.363661  [32000/60000]\n",
      "loss: 0.222792  [38400/60000]\n",
      "loss: 0.429538  [44800/60000]\n",
      "loss: 0.364612  [51200/60000]\n",
      "loss: 0.448026  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.320637 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.312662  [    0/60000]\n",
      "loss: 0.289731  [ 6400/60000]\n",
      "loss: 0.262483  [12800/60000]\n",
      "loss: 0.376447  [19200/60000]\n",
      "loss: 0.279816  [25600/60000]\n",
      "loss: 0.360159  [32000/60000]\n",
      "loss: 0.219277  [38400/60000]\n",
      "loss: 0.425483  [44800/60000]\n",
      "loss: 0.359774  [51200/60000]\n",
      "loss: 0.444822  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.317120 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.305562  [    0/60000]\n",
      "loss: 0.287357  [ 6400/60000]\n",
      "loss: 0.256761  [12800/60000]\n",
      "loss: 0.373498  [19200/60000]\n",
      "loss: 0.275210  [25600/60000]\n",
      "loss: 0.356820  [32000/60000]\n",
      "loss: 0.216025  [38400/60000]\n",
      "loss: 0.421605  [44800/60000]\n",
      "loss: 0.355162  [51200/60000]\n",
      "loss: 0.441711  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.313770 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.298825  [    0/60000]\n",
      "loss: 0.285208  [ 6400/60000]\n",
      "loss: 0.251333  [12800/60000]\n",
      "loss: 0.370742  [19200/60000]\n",
      "loss: 0.270764  [25600/60000]\n",
      "loss: 0.353588  [32000/60000]\n",
      "loss: 0.213016  [38400/60000]\n",
      "loss: 0.417893  [44800/60000]\n",
      "loss: 0.350671  [51200/60000]\n",
      "loss: 0.438700  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.310572 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.292401  [    0/60000]\n",
      "loss: 0.283175  [ 6400/60000]\n",
      "loss: 0.246215  [12800/60000]\n",
      "loss: 0.368137  [19200/60000]\n",
      "loss: 0.266438  [25600/60000]\n",
      "loss: 0.350480  [32000/60000]\n",
      "loss: 0.210202  [38400/60000]\n",
      "loss: 0.414323  [44800/60000]\n",
      "loss: 0.346256  [51200/60000]\n",
      "loss: 0.435785  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.307514 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.286263  [    0/60000]\n",
      "loss: 0.281225  [ 6400/60000]\n",
      "loss: 0.241330  [12800/60000]\n",
      "loss: 0.365579  [19200/60000]\n",
      "loss: 0.262286  [25600/60000]\n",
      "loss: 0.347457  [32000/60000]\n",
      "loss: 0.207572  [38400/60000]\n",
      "loss: 0.410875  [44800/60000]\n",
      "loss: 0.341967  [51200/60000]\n",
      "loss: 0.432951  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.304576 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.280390  [    0/60000]\n",
      "loss: 0.279347  [ 6400/60000]\n",
      "loss: 0.236724  [12800/60000]\n",
      "loss: 0.363117  [19200/60000]\n",
      "loss: 0.258231  [25600/60000]\n",
      "loss: 0.344554  [32000/60000]\n",
      "loss: 0.205077  [38400/60000]\n",
      "loss: 0.407581  [44800/60000]\n",
      "loss: 0.337696  [51200/60000]\n",
      "loss: 0.430173  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.301754 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.274754  [    0/60000]\n",
      "loss: 0.277584  [ 6400/60000]\n",
      "loss: 0.232348  [12800/60000]\n",
      "loss: 0.360747  [19200/60000]\n",
      "loss: 0.254324  [25600/60000]\n",
      "loss: 0.341735  [32000/60000]\n",
      "loss: 0.202742  [38400/60000]\n",
      "loss: 0.404389  [44800/60000]\n",
      "loss: 0.333472  [51200/60000]\n",
      "loss: 0.427456  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.299031 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.269340  [    0/60000]\n",
      "loss: 0.275940  [ 6400/60000]\n",
      "loss: 0.228200  [12800/60000]\n",
      "loss: 0.358464  [19200/60000]\n",
      "loss: 0.250545  [25600/60000]\n",
      "loss: 0.338990  [32000/60000]\n",
      "loss: 0.200523  [38400/60000]\n",
      "loss: 0.401327  [44800/60000]\n",
      "loss: 0.329304  [51200/60000]\n",
      "loss: 0.424765  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.296407 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.264153  [    0/60000]\n",
      "loss: 0.274362  [ 6400/60000]\n",
      "loss: 0.224237  [12800/60000]\n",
      "loss: 0.356282  [19200/60000]\n",
      "loss: 0.246856  [25600/60000]\n",
      "loss: 0.336301  [32000/60000]\n",
      "loss: 0.198380  [38400/60000]\n",
      "loss: 0.398372  [44800/60000]\n",
      "loss: 0.325235  [51200/60000]\n",
      "loss: 0.422122  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.293871 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.259183  [    0/60000]\n",
      "loss: 0.272864  [ 6400/60000]\n",
      "loss: 0.220476  [12800/60000]\n",
      "loss: 0.354169  [19200/60000]\n",
      "loss: 0.243298  [25600/60000]\n",
      "loss: 0.333658  [32000/60000]\n",
      "loss: 0.196373  [38400/60000]\n",
      "loss: 0.395489  [44800/60000]\n",
      "loss: 0.321230  [51200/60000]\n",
      "loss: 0.419541  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.291418 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.254416  [    0/60000]\n",
      "loss: 0.271406  [ 6400/60000]\n",
      "loss: 0.216887  [12800/60000]\n",
      "loss: 0.352142  [19200/60000]\n",
      "loss: 0.239856  [25600/60000]\n",
      "loss: 0.331138  [32000/60000]\n",
      "loss: 0.194466  [38400/60000]\n",
      "loss: 0.392740  [44800/60000]\n",
      "loss: 0.317311  [51200/60000]\n",
      "loss: 0.417010  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.289034 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.249825  [    0/60000]\n",
      "loss: 0.269919  [ 6400/60000]\n",
      "loss: 0.213424  [12800/60000]\n",
      "loss: 0.350162  [19200/60000]\n",
      "loss: 0.236515  [25600/60000]\n",
      "loss: 0.328703  [32000/60000]\n",
      "loss: 0.192657  [38400/60000]\n",
      "loss: 0.390089  [44800/60000]\n",
      "loss: 0.313495  [51200/60000]\n",
      "loss: 0.414490  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.286717 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.245408  [    0/60000]\n",
      "loss: 0.268389  [ 6400/60000]\n",
      "loss: 0.210099  [12800/60000]\n",
      "loss: 0.348198  [19200/60000]\n",
      "loss: 0.233276  [25600/60000]\n",
      "loss: 0.326328  [32000/60000]\n",
      "loss: 0.190925  [38400/60000]\n",
      "loss: 0.387508  [44800/60000]\n",
      "loss: 0.309777  [51200/60000]\n",
      "loss: 0.412082  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.284459 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.241116  [    0/60000]\n",
      "loss: 0.266878  [ 6400/60000]\n",
      "loss: 0.206915  [12800/60000]\n",
      "loss: 0.346212  [19200/60000]\n",
      "loss: 0.230157  [25600/60000]\n",
      "loss: 0.324036  [32000/60000]\n",
      "loss: 0.189222  [38400/60000]\n",
      "loss: 0.384998  [44800/60000]\n",
      "loss: 0.306069  [51200/60000]\n",
      "loss: 0.409706  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.282260 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.236973  [    0/60000]\n",
      "loss: 0.265405  [ 6400/60000]\n",
      "loss: 0.203908  [12800/60000]\n",
      "loss: 0.344264  [19200/60000]\n",
      "loss: 0.227086  [25600/60000]\n",
      "loss: 0.321814  [32000/60000]\n",
      "loss: 0.187587  [38400/60000]\n",
      "loss: 0.382574  [44800/60000]\n",
      "loss: 0.302411  [51200/60000]\n",
      "loss: 0.407357  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.280117 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.232959  [    0/60000]\n",
      "loss: 0.263968  [ 6400/60000]\n",
      "loss: 0.200997  [12800/60000]\n",
      "loss: 0.342371  [19200/60000]\n",
      "loss: 0.224101  [25600/60000]\n",
      "loss: 0.319699  [32000/60000]\n",
      "loss: 0.185976  [38400/60000]\n",
      "loss: 0.380147  [44800/60000]\n",
      "loss: 0.298840  [51200/60000]\n",
      "loss: 0.404993  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.278023 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.229069  [    0/60000]\n",
      "loss: 0.262574  [ 6400/60000]\n",
      "loss: 0.198183  [12800/60000]\n",
      "loss: 0.340485  [19200/60000]\n",
      "loss: 0.221163  [25600/60000]\n",
      "loss: 0.317649  [32000/60000]\n",
      "loss: 0.184429  [38400/60000]\n",
      "loss: 0.377802  [44800/60000]\n",
      "loss: 0.295354  [51200/60000]\n",
      "loss: 0.402590  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.275981 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.225373  [    0/60000]\n",
      "loss: 0.261210  [ 6400/60000]\n",
      "loss: 0.195483  [12800/60000]\n",
      "loss: 0.338638  [19200/60000]\n",
      "loss: 0.218278  [25600/60000]\n",
      "loss: 0.315653  [32000/60000]\n",
      "loss: 0.182939  [38400/60000]\n",
      "loss: 0.375541  [44800/60000]\n",
      "loss: 0.291998  [51200/60000]\n",
      "loss: 0.400291  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.273974 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.221797  [    0/60000]\n",
      "loss: 0.259870  [ 6400/60000]\n",
      "loss: 0.192879  [12800/60000]\n",
      "loss: 0.336813  [19200/60000]\n",
      "loss: 0.215510  [25600/60000]\n",
      "loss: 0.313697  [32000/60000]\n",
      "loss: 0.181498  [38400/60000]\n",
      "loss: 0.373374  [44800/60000]\n",
      "loss: 0.288653  [51200/60000]\n",
      "loss: 0.398004  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.272007 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.218332  [    0/60000]\n",
      "loss: 0.258520  [ 6400/60000]\n",
      "loss: 0.190369  [12800/60000]\n",
      "loss: 0.335031  [19200/60000]\n",
      "loss: 0.212832  [25600/60000]\n",
      "loss: 0.311763  [32000/60000]\n",
      "loss: 0.180084  [38400/60000]\n",
      "loss: 0.371392  [44800/60000]\n",
      "loss: 0.285355  [51200/60000]\n",
      "loss: 0.395755  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.270083 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.215023  [    0/60000]\n",
      "loss: 0.257195  [ 6400/60000]\n",
      "loss: 0.187936  [12800/60000]\n",
      "loss: 0.333311  [19200/60000]\n",
      "loss: 0.210218  [25600/60000]\n",
      "loss: 0.309901  [32000/60000]\n",
      "loss: 0.178689  [38400/60000]\n",
      "loss: 0.369468  [44800/60000]\n",
      "loss: 0.282130  [51200/60000]\n",
      "loss: 0.393559  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.268194 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.211807  [    0/60000]\n",
      "loss: 0.255908  [ 6400/60000]\n",
      "loss: 0.185588  [12800/60000]\n",
      "loss: 0.331623  [19200/60000]\n",
      "loss: 0.207653  [25600/60000]\n",
      "loss: 0.308079  [32000/60000]\n",
      "loss: 0.177311  [38400/60000]\n",
      "loss: 0.367618  [44800/60000]\n",
      "loss: 0.278964  [51200/60000]\n",
      "loss: 0.391396  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.266340 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.208715  [    0/60000]\n",
      "loss: 0.254649  [ 6400/60000]\n",
      "loss: 0.183333  [12800/60000]\n",
      "loss: 0.329957  [19200/60000]\n",
      "loss: 0.205167  [25600/60000]\n",
      "loss: 0.306290  [32000/60000]\n",
      "loss: 0.175973  [38400/60000]\n",
      "loss: 0.365839  [44800/60000]\n",
      "loss: 0.275813  [51200/60000]\n",
      "loss: 0.389192  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.264520 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.205681  [    0/60000]\n",
      "loss: 0.253425  [ 6400/60000]\n",
      "loss: 0.181169  [12800/60000]\n",
      "loss: 0.328251  [19200/60000]\n",
      "loss: 0.202783  [25600/60000]\n",
      "loss: 0.304549  [32000/60000]\n",
      "loss: 0.174685  [38400/60000]\n",
      "loss: 0.364124  [44800/60000]\n",
      "loss: 0.272676  [51200/60000]\n",
      "loss: 0.387024  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.262732 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.202700  [    0/60000]\n",
      "loss: 0.252214  [ 6400/60000]\n",
      "loss: 0.179075  [12800/60000]\n",
      "loss: 0.326489  [19200/60000]\n",
      "loss: 0.200473  [25600/60000]\n",
      "loss: 0.302857  [32000/60000]\n",
      "loss: 0.173400  [38400/60000]\n",
      "loss: 0.362451  [44800/60000]\n",
      "loss: 0.269608  [51200/60000]\n",
      "loss: 0.384864  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.260972 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.199801  [    0/60000]\n",
      "loss: 0.250987  [ 6400/60000]\n",
      "loss: 0.177066  [12800/60000]\n",
      "loss: 0.324758  [19200/60000]\n",
      "loss: 0.198183  [25600/60000]\n",
      "loss: 0.301217  [32000/60000]\n",
      "loss: 0.172138  [38400/60000]\n",
      "loss: 0.360828  [44800/60000]\n",
      "loss: 0.266615  [51200/60000]\n",
      "loss: 0.382750  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.259239 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.196979  [    0/60000]\n",
      "loss: 0.249775  [ 6400/60000]\n",
      "loss: 0.175124  [12800/60000]\n",
      "loss: 0.323034  [19200/60000]\n",
      "loss: 0.195919  [25600/60000]\n",
      "loss: 0.299597  [32000/60000]\n",
      "loss: 0.170944  [38400/60000]\n",
      "loss: 0.359191  [44800/60000]\n",
      "loss: 0.263589  [51200/60000]\n",
      "loss: 0.380627  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.257531 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.194243  [    0/60000]\n",
      "loss: 0.248562  [ 6400/60000]\n",
      "loss: 0.173244  [12800/60000]\n",
      "loss: 0.321321  [19200/60000]\n",
      "loss: 0.193696  [25600/60000]\n",
      "loss: 0.298014  [32000/60000]\n",
      "loss: 0.169774  [38400/60000]\n",
      "loss: 0.357600  [44800/60000]\n",
      "loss: 0.260572  [51200/60000]\n",
      "loss: 0.378567  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.255848 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.191581  [    0/60000]\n",
      "loss: 0.247366  [ 6400/60000]\n",
      "loss: 0.171418  [12800/60000]\n",
      "loss: 0.319590  [19200/60000]\n",
      "loss: 0.191518  [25600/60000]\n",
      "loss: 0.296501  [32000/60000]\n",
      "loss: 0.168581  [38400/60000]\n",
      "loss: 0.356026  [44800/60000]\n",
      "loss: 0.257563  [51200/60000]\n",
      "loss: 0.376521  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.254189 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.188985  [    0/60000]\n",
      "loss: 0.246120  [ 6400/60000]\n",
      "loss: 0.169646  [12800/60000]\n",
      "loss: 0.317893  [19200/60000]\n",
      "loss: 0.189400  [25600/60000]\n",
      "loss: 0.295055  [32000/60000]\n",
      "loss: 0.167366  [38400/60000]\n",
      "loss: 0.354506  [44800/60000]\n",
      "loss: 0.254574  [51200/60000]\n",
      "loss: 0.374480  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.252550 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.186444  [    0/60000]\n",
      "loss: 0.244914  [ 6400/60000]\n",
      "loss: 0.167934  [12800/60000]\n",
      "loss: 0.316193  [19200/60000]\n",
      "loss: 0.187339  [25600/60000]\n",
      "loss: 0.293651  [32000/60000]\n",
      "loss: 0.166160  [38400/60000]\n",
      "loss: 0.353029  [44800/60000]\n",
      "loss: 0.251645  [51200/60000]\n",
      "loss: 0.372444  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Avg loss: 0.250932 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.183964  [    0/60000]\n",
      "loss: 0.243672  [ 6400/60000]\n",
      "loss: 0.166290  [12800/60000]\n",
      "loss: 0.314509  [19200/60000]\n",
      "loss: 0.185350  [25600/60000]\n",
      "loss: 0.292257  [32000/60000]\n",
      "loss: 0.164963  [38400/60000]\n",
      "loss: 0.351580  [44800/60000]\n",
      "loss: 0.248766  [51200/60000]\n",
      "loss: 0.370410  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.249340 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.181556  [    0/60000]\n",
      "loss: 0.242454  [ 6400/60000]\n",
      "loss: 0.164704  [12800/60000]\n",
      "loss: 0.312848  [19200/60000]\n",
      "loss: 0.183411  [25600/60000]\n",
      "loss: 0.290914  [32000/60000]\n",
      "loss: 0.163765  [38400/60000]\n",
      "loss: 0.350151  [44800/60000]\n",
      "loss: 0.245928  [51200/60000]\n",
      "loss: 0.368407  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.247765 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.179219  [    0/60000]\n",
      "loss: 0.241250  [ 6400/60000]\n",
      "loss: 0.163174  [12800/60000]\n",
      "loss: 0.311229  [19200/60000]\n",
      "loss: 0.181527  [25600/60000]\n",
      "loss: 0.289613  [32000/60000]\n",
      "loss: 0.162554  [38400/60000]\n",
      "loss: 0.348750  [44800/60000]\n",
      "loss: 0.243062  [51200/60000]\n",
      "loss: 0.366446  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.246208 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.176936  [    0/60000]\n",
      "loss: 0.240069  [ 6400/60000]\n",
      "loss: 0.161665  [12800/60000]\n",
      "loss: 0.309630  [19200/60000]\n",
      "loss: 0.179687  [25600/60000]\n",
      "loss: 0.288338  [32000/60000]\n",
      "loss: 0.161373  [38400/60000]\n",
      "loss: 0.347350  [44800/60000]\n",
      "loss: 0.240285  [51200/60000]\n",
      "loss: 0.364526  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.244665 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.174720  [    0/60000]\n",
      "loss: 0.238910  [ 6400/60000]\n",
      "loss: 0.160206  [12800/60000]\n",
      "loss: 0.308049  [19200/60000]\n",
      "loss: 0.177919  [25600/60000]\n",
      "loss: 0.287097  [32000/60000]\n",
      "loss: 0.160194  [38400/60000]\n",
      "loss: 0.345974  [44800/60000]\n",
      "loss: 0.237545  [51200/60000]\n",
      "loss: 0.362594  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.243138 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.172588  [    0/60000]\n",
      "loss: 0.237760  [ 6400/60000]\n",
      "loss: 0.158784  [12800/60000]\n",
      "loss: 0.306427  [19200/60000]\n",
      "loss: 0.176156  [25600/60000]\n",
      "loss: 0.285894  [32000/60000]\n",
      "loss: 0.159030  [38400/60000]\n",
      "loss: 0.344563  [44800/60000]\n",
      "loss: 0.234868  [51200/60000]\n",
      "loss: 0.360709  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.241628 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.170516  [    0/60000]\n",
      "loss: 0.236640  [ 6400/60000]\n",
      "loss: 0.157396  [12800/60000]\n",
      "loss: 0.304830  [19200/60000]\n",
      "loss: 0.174458  [25600/60000]\n",
      "loss: 0.284690  [32000/60000]\n",
      "loss: 0.157896  [38400/60000]\n",
      "loss: 0.343164  [44800/60000]\n",
      "loss: 0.232228  [51200/60000]\n",
      "loss: 0.358857  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.240139 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.168505  [    0/60000]\n",
      "loss: 0.235529  [ 6400/60000]\n",
      "loss: 0.156038  [12800/60000]\n",
      "loss: 0.303266  [19200/60000]\n",
      "loss: 0.172779  [25600/60000]\n",
      "loss: 0.283484  [32000/60000]\n",
      "loss: 0.156762  [38400/60000]\n",
      "loss: 0.341808  [44800/60000]\n",
      "loss: 0.229630  [51200/60000]\n",
      "loss: 0.357026  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.238665 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.166551  [    0/60000]\n",
      "loss: 0.234443  [ 6400/60000]\n",
      "loss: 0.154708  [12800/60000]\n",
      "loss: 0.301634  [19200/60000]\n",
      "loss: 0.171118  [25600/60000]\n",
      "loss: 0.282243  [32000/60000]\n",
      "loss: 0.155670  [38400/60000]\n",
      "loss: 0.340413  [44800/60000]\n",
      "loss: 0.227118  [51200/60000]\n",
      "loss: 0.355218  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.237209 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.164681  [    0/60000]\n",
      "loss: 0.233353  [ 6400/60000]\n",
      "loss: 0.153410  [12800/60000]\n",
      "loss: 0.300025  [19200/60000]\n",
      "loss: 0.169518  [25600/60000]\n",
      "loss: 0.281039  [32000/60000]\n",
      "loss: 0.154574  [38400/60000]\n",
      "loss: 0.339000  [44800/60000]\n",
      "loss: 0.224645  [51200/60000]\n",
      "loss: 0.353427  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.235768 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.162872  [    0/60000]\n",
      "loss: 0.232275  [ 6400/60000]\n",
      "loss: 0.152153  [12800/60000]\n",
      "loss: 0.298417  [19200/60000]\n",
      "loss: 0.167925  [25600/60000]\n",
      "loss: 0.279854  [32000/60000]\n",
      "loss: 0.153469  [38400/60000]\n",
      "loss: 0.337553  [44800/60000]\n",
      "loss: 0.222196  [51200/60000]\n",
      "loss: 0.351668  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.234340 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.161093  [    0/60000]\n",
      "loss: 0.231246  [ 6400/60000]\n",
      "loss: 0.150922  [12800/60000]\n",
      "loss: 0.296768  [19200/60000]\n",
      "loss: 0.166380  [25600/60000]\n",
      "loss: 0.278668  [32000/60000]\n",
      "loss: 0.152349  [38400/60000]\n",
      "loss: 0.336114  [44800/60000]\n",
      "loss: 0.219796  [51200/60000]\n",
      "loss: 0.349937  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.232925 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.159358  [    0/60000]\n",
      "loss: 0.230243  [ 6400/60000]\n",
      "loss: 0.149718  [12800/60000]\n",
      "loss: 0.295137  [19200/60000]\n",
      "loss: 0.164874  [25600/60000]\n",
      "loss: 0.277498  [32000/60000]\n",
      "loss: 0.151254  [38400/60000]\n",
      "loss: 0.334639  [44800/60000]\n",
      "loss: 0.217438  [51200/60000]\n",
      "loss: 0.348200  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.231519 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.157650  [    0/60000]\n",
      "loss: 0.229271  [ 6400/60000]\n",
      "loss: 0.148541  [12800/60000]\n",
      "loss: 0.293483  [19200/60000]\n",
      "loss: 0.163403  [25600/60000]\n",
      "loss: 0.276362  [32000/60000]\n",
      "loss: 0.150167  [38400/60000]\n",
      "loss: 0.333169  [44800/60000]\n",
      "loss: 0.215137  [51200/60000]\n",
      "loss: 0.346450  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.230125 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.155994  [    0/60000]\n",
      "loss: 0.228286  [ 6400/60000]\n",
      "loss: 0.147406  [12800/60000]\n",
      "loss: 0.291843  [19200/60000]\n",
      "loss: 0.161988  [25600/60000]\n",
      "loss: 0.275224  [32000/60000]\n",
      "loss: 0.149078  [38400/60000]\n",
      "loss: 0.331713  [44800/60000]\n",
      "loss: 0.212875  [51200/60000]\n",
      "loss: 0.344716  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.228744 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.154379  [    0/60000]\n",
      "loss: 0.227310  [ 6400/60000]\n",
      "loss: 0.146297  [12800/60000]\n",
      "loss: 0.290175  [19200/60000]\n",
      "loss: 0.160594  [25600/60000]\n",
      "loss: 0.274099  [32000/60000]\n",
      "loss: 0.148009  [38400/60000]\n",
      "loss: 0.330256  [44800/60000]\n",
      "loss: 0.210672  [51200/60000]\n",
      "loss: 0.343005  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.227376 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.152808  [    0/60000]\n",
      "loss: 0.226367  [ 6400/60000]\n",
      "loss: 0.145217  [12800/60000]\n",
      "loss: 0.288494  [19200/60000]\n",
      "loss: 0.159198  [25600/60000]\n",
      "loss: 0.272994  [32000/60000]\n",
      "loss: 0.146921  [38400/60000]\n",
      "loss: 0.328775  [44800/60000]\n",
      "loss: 0.208524  [51200/60000]\n",
      "loss: 0.341307  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.226023 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.151287  [    0/60000]\n",
      "loss: 0.225428  [ 6400/60000]\n",
      "loss: 0.144139  [12800/60000]\n",
      "loss: 0.286857  [19200/60000]\n",
      "loss: 0.157845  [25600/60000]\n",
      "loss: 0.271900  [32000/60000]\n",
      "loss: 0.145826  [38400/60000]\n",
      "loss: 0.327301  [44800/60000]\n",
      "loss: 0.206412  [51200/60000]\n",
      "loss: 0.339662  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.224681 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.149818  [    0/60000]\n",
      "loss: 0.224496  [ 6400/60000]\n",
      "loss: 0.143090  [12800/60000]\n",
      "loss: 0.285246  [19200/60000]\n",
      "loss: 0.156507  [25600/60000]\n",
      "loss: 0.270777  [32000/60000]\n",
      "loss: 0.144761  [38400/60000]\n",
      "loss: 0.325820  [44800/60000]\n",
      "loss: 0.204345  [51200/60000]\n",
      "loss: 0.338034  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.223355 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.148379  [    0/60000]\n",
      "loss: 0.223572  [ 6400/60000]\n",
      "loss: 0.142065  [12800/60000]\n",
      "loss: 0.283630  [19200/60000]\n",
      "loss: 0.155196  [25600/60000]\n",
      "loss: 0.269682  [32000/60000]\n",
      "loss: 0.143697  [38400/60000]\n",
      "loss: 0.324351  [44800/60000]\n",
      "loss: 0.202305  [51200/60000]\n",
      "loss: 0.336401  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.222041 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.146984  [    0/60000]\n",
      "loss: 0.222646  [ 6400/60000]\n",
      "loss: 0.141081  [12800/60000]\n",
      "loss: 0.282054  [19200/60000]\n",
      "loss: 0.153927  [25600/60000]\n",
      "loss: 0.268606  [32000/60000]\n",
      "loss: 0.142650  [38400/60000]\n",
      "loss: 0.322900  [44800/60000]\n",
      "loss: 0.200280  [51200/60000]\n",
      "loss: 0.334795  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.220736 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.145614  [    0/60000]\n",
      "loss: 0.221760  [ 6400/60000]\n",
      "loss: 0.140105  [12800/60000]\n",
      "loss: 0.280482  [19200/60000]\n",
      "loss: 0.152695  [25600/60000]\n",
      "loss: 0.267551  [32000/60000]\n",
      "loss: 0.141623  [38400/60000]\n",
      "loss: 0.321471  [44800/60000]\n",
      "loss: 0.198249  [51200/60000]\n",
      "loss: 0.333265  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.219440 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.144278  [    0/60000]\n",
      "loss: 0.220841  [ 6400/60000]\n",
      "loss: 0.139136  [12800/60000]\n",
      "loss: 0.278937  [19200/60000]\n",
      "loss: 0.151503  [25600/60000]\n",
      "loss: 0.266509  [32000/60000]\n",
      "loss: 0.140601  [38400/60000]\n",
      "loss: 0.320062  [44800/60000]\n",
      "loss: 0.196276  [51200/60000]\n",
      "loss: 0.331763  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.218158 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.142965  [    0/60000]\n",
      "loss: 0.219914  [ 6400/60000]\n",
      "loss: 0.138188  [12800/60000]\n",
      "loss: 0.277372  [19200/60000]\n",
      "loss: 0.150338  [25600/60000]\n",
      "loss: 0.265530  [32000/60000]\n",
      "loss: 0.139586  [38400/60000]\n",
      "loss: 0.318646  [44800/60000]\n",
      "loss: 0.194349  [51200/60000]\n",
      "loss: 0.330289  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.216883 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.141665  [    0/60000]\n",
      "loss: 0.219034  [ 6400/60000]\n",
      "loss: 0.137260  [12800/60000]\n",
      "loss: 0.275789  [19200/60000]\n",
      "loss: 0.149179  [25600/60000]\n",
      "loss: 0.264551  [32000/60000]\n",
      "loss: 0.138587  [38400/60000]\n",
      "loss: 0.317234  [44800/60000]\n",
      "loss: 0.192467  [51200/60000]\n",
      "loss: 0.328836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.215622 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.140379  [    0/60000]\n",
      "loss: 0.218192  [ 6400/60000]\n",
      "loss: 0.136348  [12800/60000]\n",
      "loss: 0.274211  [19200/60000]\n",
      "loss: 0.148040  [25600/60000]\n",
      "loss: 0.263564  [32000/60000]\n",
      "loss: 0.137606  [38400/60000]\n",
      "loss: 0.315800  [44800/60000]\n",
      "loss: 0.190625  [51200/60000]\n",
      "loss: 0.327387  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.214374 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.139113  [    0/60000]\n",
      "loss: 0.217350  [ 6400/60000]\n",
      "loss: 0.135446  [12800/60000]\n",
      "loss: 0.272678  [19200/60000]\n",
      "loss: 0.146903  [25600/60000]\n",
      "loss: 0.262564  [32000/60000]\n",
      "loss: 0.136631  [38400/60000]\n",
      "loss: 0.314355  [44800/60000]\n",
      "loss: 0.188795  [51200/60000]\n",
      "loss: 0.325970  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.213139 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.137892  [    0/60000]\n",
      "loss: 0.216517  [ 6400/60000]\n",
      "loss: 0.134568  [12800/60000]\n",
      "loss: 0.271183  [19200/60000]\n",
      "loss: 0.145811  [25600/60000]\n",
      "loss: 0.261571  [32000/60000]\n",
      "loss: 0.135652  [38400/60000]\n",
      "loss: 0.312917  [44800/60000]\n",
      "loss: 0.187051  [51200/60000]\n",
      "loss: 0.324549  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.211912 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.136677  [    0/60000]\n",
      "loss: 0.215713  [ 6400/60000]\n",
      "loss: 0.133715  [12800/60000]\n",
      "loss: 0.269663  [19200/60000]\n",
      "loss: 0.144750  [25600/60000]\n",
      "loss: 0.260581  [32000/60000]\n",
      "loss: 0.134697  [38400/60000]\n",
      "loss: 0.311460  [44800/60000]\n",
      "loss: 0.185353  [51200/60000]\n",
      "loss: 0.323114  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.210694 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.135487  [    0/60000]\n",
      "loss: 0.214929  [ 6400/60000]\n",
      "loss: 0.132873  [12800/60000]\n",
      "loss: 0.268142  [19200/60000]\n",
      "loss: 0.143710  [25600/60000]\n",
      "loss: 0.259597  [32000/60000]\n",
      "loss: 0.133758  [38400/60000]\n",
      "loss: 0.309981  [44800/60000]\n",
      "loss: 0.183680  [51200/60000]\n",
      "loss: 0.321710  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.209485 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.134315  [    0/60000]\n",
      "loss: 0.214152  [ 6400/60000]\n",
      "loss: 0.132061  [12800/60000]\n",
      "loss: 0.266640  [19200/60000]\n",
      "loss: 0.142694  [25600/60000]\n",
      "loss: 0.258652  [32000/60000]\n",
      "loss: 0.132813  [38400/60000]\n",
      "loss: 0.308514  [44800/60000]\n",
      "loss: 0.182094  [51200/60000]\n",
      "loss: 0.320328  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.208285 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.133186  [    0/60000]\n",
      "loss: 0.213417  [ 6400/60000]\n",
      "loss: 0.131258  [12800/60000]\n",
      "loss: 0.265155  [19200/60000]\n",
      "loss: 0.141700  [25600/60000]\n",
      "loss: 0.257732  [32000/60000]\n",
      "loss: 0.131885  [38400/60000]\n",
      "loss: 0.307068  [44800/60000]\n",
      "loss: 0.180576  [51200/60000]\n",
      "loss: 0.318950  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.207096 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.132059  [    0/60000]\n",
      "loss: 0.212672  [ 6400/60000]\n",
      "loss: 0.130469  [12800/60000]\n",
      "loss: 0.263705  [19200/60000]\n",
      "loss: 0.140738  [25600/60000]\n",
      "loss: 0.256809  [32000/60000]\n",
      "loss: 0.130961  [38400/60000]\n",
      "loss: 0.305661  [44800/60000]\n",
      "loss: 0.179129  [51200/60000]\n",
      "loss: 0.317587  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.205916 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.130948  [    0/60000]\n",
      "loss: 0.211932  [ 6400/60000]\n",
      "loss: 0.129684  [12800/60000]\n",
      "loss: 0.262275  [19200/60000]\n",
      "loss: 0.139816  [25600/60000]\n",
      "loss: 0.255906  [32000/60000]\n",
      "loss: 0.130031  [38400/60000]\n",
      "loss: 0.304210  [44800/60000]\n",
      "loss: 0.177700  [51200/60000]\n",
      "loss: 0.316220  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.204745 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.129853  [    0/60000]\n",
      "loss: 0.211257  [ 6400/60000]\n",
      "loss: 0.128912  [12800/60000]\n",
      "loss: 0.260824  [19200/60000]\n",
      "loss: 0.138915  [25600/60000]\n",
      "loss: 0.255007  [32000/60000]\n",
      "loss: 0.129098  [38400/60000]\n",
      "loss: 0.302761  [44800/60000]\n",
      "loss: 0.176350  [51200/60000]\n",
      "loss: 0.314860  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.203584 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.128763  [    0/60000]\n",
      "loss: 0.210572  [ 6400/60000]\n",
      "loss: 0.128144  [12800/60000]\n",
      "loss: 0.259354  [19200/60000]\n",
      "loss: 0.138012  [25600/60000]\n",
      "loss: 0.254094  [32000/60000]\n",
      "loss: 0.128150  [38400/60000]\n",
      "loss: 0.301311  [44800/60000]\n",
      "loss: 0.175037  [51200/60000]\n",
      "loss: 0.313523  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.202433 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.127691  [    0/60000]\n",
      "loss: 0.209880  [ 6400/60000]\n",
      "loss: 0.127387  [12800/60000]\n",
      "loss: 0.257909  [19200/60000]\n",
      "loss: 0.137125  [25600/60000]\n",
      "loss: 0.253180  [32000/60000]\n",
      "loss: 0.127211  [38400/60000]\n",
      "loss: 0.299841  [44800/60000]\n",
      "loss: 0.173741  [51200/60000]\n",
      "loss: 0.312178  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.201293 \n",
      "\n",
      "Done in  616.8470742702484 seconds.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T12:12:27.280759300Z",
     "start_time": "2026-01-27T12:12:27.210715500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = model(X.to(device))\n",
    "preds"
   ],
   "id": "b07122297c99f479",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.0982,  -6.2945,   2.8717,   3.7953,  -4.3522,  -0.0259,  -8.9193,\n",
       "           9.7012,  -0.3841,   2.9270],\n",
       "        [  3.5577,  -0.8030,   9.8070,   5.4645, -10.1232,   3.2213,   4.4077,\n",
       "          -8.8510,   2.2675,  -8.8998],\n",
       "        [ -5.6424,   6.3494,   1.2674,   0.3567,  -1.5939,  -0.2124,  -0.1403,\n",
       "           0.7983,   0.4748,  -2.0508],\n",
       "        [ 11.3917, -12.0343,   2.8377,  -0.3463,  -6.1899,   3.0261,   1.6825,\n",
       "           0.3308,   0.2076,   0.1232],\n",
       "        [ -1.2799,  -6.7455,   0.4093,  -2.8538,   6.9129,  -0.5899,   0.3805,\n",
       "           0.9622,   0.4429,   3.4206],\n",
       "        [ -7.1537,   7.5657,   0.9538,   1.1664,  -1.9223,  -1.3030,  -2.3588,\n",
       "           2.4416,   1.0329,  -0.7722],\n",
       "        [ -4.5124,  -4.8262,  -3.7733,  -0.9931,   7.9162,   2.1766,  -2.1283,\n",
       "           0.7439,   3.1912,   3.2901],\n",
       "        [ -6.5002,  -0.7971,  -0.7856,   1.1646,   1.7775,   0.3500,  -3.6136,\n",
       "           1.2797,   1.5422,   5.8531],\n",
       "        [  1.1486,  -6.1332,   2.1579,  -5.9013,   4.0267,   3.7393,   8.5357,\n",
       "          -6.6499,   1.4753,  -1.3441],\n",
       "        [ -2.6941,  -8.4688,  -2.2743,  -2.0190,   5.1542,  -0.5223,  -5.4537,\n",
       "           5.3684,   3.4747,   9.1568],\n",
       "        [ 10.0397,  -8.2994,   3.5185,   0.6716,  -5.2590,   5.2042,  -0.3022,\n",
       "          -4.1419,   2.6355,  -3.5327],\n",
       "        [  0.2447,  -2.7347,   2.4301,  -0.6106,   0.2672,   0.0304,   6.4125,\n",
       "          -4.3822,   2.7791,  -3.3668],\n",
       "        [ -1.9819,  -7.3234,  -1.3812,   0.4709,   3.5313,   0.3259,  -5.4679,\n",
       "           3.4981,   1.4914,   7.8077],\n",
       "        [  9.4973, -10.5946,   1.6756,  -0.7772,  -4.0750,   3.5861,  -3.8085,\n",
       "          -0.2599,   2.3827,   3.0614],\n",
       "        [ -8.7419,   9.5246,   0.1338,   2.5742,  -3.5192,  -0.4480,  -1.2518,\n",
       "           0.0500,   1.9855,  -0.8445],\n",
       "        [ -0.2837,  -1.2275,  -0.7082,   3.4371,  -3.0923,   6.2361,  -3.1331,\n",
       "          -2.2070,   2.7796,  -2.0847],\n",
       "        [ -0.6806,  -8.9360,   0.4884,  -1.2557,   3.5991,  -1.1101,  -3.7404,\n",
       "           3.8446,   1.2200,   7.8309],\n",
       "        [  1.8113,  -7.0078,   3.2609,   5.6938,  -5.8886,  -0.1883,  -8.7090,\n",
       "          10.5701,  -1.4899,   2.5056],\n",
       "        [ -3.7150,  -0.6581,   2.4351,   5.7915,  -2.8459,   0.4221,   0.5704,\n",
       "          -1.6637,   1.7717,  -1.9797],\n",
       "        [ -2.6673,  -5.2778,  -1.0291,  -1.0585,   7.9158,   0.3802,  -0.2179,\n",
       "           0.3373,  -0.6661,   3.1417],\n",
       "        [ -3.0952,  -5.5370,  -5.0639,   2.7730,   3.4852,   1.8378, -10.1934,\n",
       "           6.2310,   1.6130,   9.0688],\n",
       "        [ -0.5347,  -4.2339,   0.9763,  -1.0495,   1.1271,   4.1494,   8.3248,\n",
       "          -7.1758,   1.6224,  -2.3251],\n",
       "        [ -3.9929,  -1.0667,   1.7210,  -1.9880,   2.8299,  -2.1330,   5.9339,\n",
       "           1.1569,   0.1980,  -1.4894],\n",
       "        [  0.8477,  -4.3554,  -0.8927,   0.0358,   0.8271,   8.1478,   2.3592,\n",
       "          -6.1748,   1.0044,  -1.5544],\n",
       "        [ -2.6740,  -4.2982,  -0.5465,  -1.2555,   6.1487,   0.0404,  -0.5637,\n",
       "           2.1372,  -1.5805,   3.0725],\n",
       "        [ 16.5035, -17.2560,   3.7849,  -6.0942,  -1.5066,   5.2448,   6.3439,\n",
       "          -4.4056,   2.3453,  -3.2203],\n",
       "        [ -0.1656,  -4.0882,   0.1601,   1.9927,  -2.4053,   0.9383,  -6.4420,\n",
       "           7.4399,  -0.9618,   3.7062],\n",
       "        [ -2.2505,  -7.5595,  -0.7590,  -2.4450,   8.9339,   1.4017,  -0.5262,\n",
       "          -0.4097,   0.4791,   4.0498],\n",
       "        [ 12.6019, -12.2860,   3.9897,   2.7113,  -8.0708,   3.3424,  -4.3713,\n",
       "          -0.7671,   2.4617,   1.1774],\n",
       "        [ -6.2074,   6.4114,  -0.5216,   1.1188,  -1.9931,   2.0100,   0.1348,\n",
       "          -1.9091,   2.4712,  -1.8976],\n",
       "        [ -3.4894,  -1.6126,  -1.9462,   9.6933,  -5.5535,   3.4878,  -8.0256,\n",
       "           2.9564,   0.9847,   3.5216],\n",
       "        [ -6.3990,   5.9733,  -1.0876,   1.6556,  -1.2629,   0.4978,  -1.9275,\n",
       "           0.6640,   0.8235,   0.4590],\n",
       "        [ -3.2912,  -2.0912,  -0.3715,   9.2678,  -2.3601,   5.4460,  -5.1922,\n",
       "          -4.7170,   3.3454,  -0.2135],\n",
       "        [  4.7251,  -7.5968,   2.3001,  -5.3331,   2.9948,   2.8621,   5.1131,\n",
       "          -2.9790,   0.3260,  -1.8204],\n",
       "        [ -2.1242,  -4.7692,   5.2060,   4.7888,  -4.4467,  -2.1245, -11.2185,\n",
       "          10.7149,   0.5309,   3.9254],\n",
       "        [  0.7152,  -1.3229,   9.9209,   3.7725,  -6.6952,   2.7980,  -0.7332,\n",
       "          -3.6549,   3.0165,  -8.0406],\n",
       "        [ -0.3246,  -6.0260,   2.9689,   4.6328,  -4.9638,   0.1671,  -7.8863,\n",
       "           8.4723,  -0.0949,   3.6023],\n",
       "        [ -8.0862,   8.3536,  -0.6244,   0.9718,  -2.3480,   0.6629,  -1.3954,\n",
       "           0.2338,   2.3350,  -0.6362],\n",
       "        [  1.7558,   0.3848,   5.7931,   4.8702,  -9.4717,   2.9505,   0.0716,\n",
       "          -4.2677,   2.0531,  -4.3484],\n",
       "        [ -7.3034,   8.2209,  -0.0878,   1.7978,  -3.8350,   0.4619,  -0.5202,\n",
       "          -2.0718,   4.0029,  -0.8277],\n",
       "        [ -4.6436,   5.5744,   0.6869,   0.6724,  -2.2043,   0.2197,  -0.7067,\n",
       "           0.4861,   0.4662,  -0.9968],\n",
       "        [ -1.8250,  -4.6163,   2.2618,   2.7764,  -2.7717,   0.1584,  -6.3174,\n",
       "           7.4522,  -0.9370,   4.1383],\n",
       "        [ -7.6503,  -2.7230,  -2.1768,  -0.0219,   8.2377,  -1.5567,  -3.8311,\n",
       "           2.9216,   2.7633,   5.2339],\n",
       "        [ -2.2632,   1.7432,   5.1203,   1.6628,  -2.0220,  -0.3987,   0.3818,\n",
       "          -2.2195,   1.4185,  -3.6101],\n",
       "        [ -3.3467,   0.5135,   0.9635,   5.5677,  -3.3260,   2.7125,   0.3118,\n",
       "          -3.0745,   1.3765,  -1.7449],\n",
       "        [  1.4959,  -4.0562,  -2.2858,   2.5654,  -1.0269,   6.5854,  -1.1118,\n",
       "          -4.9585,   2.5625,   0.4918],\n",
       "        [ -9.0992,   5.9748,   0.7079,   4.5723,  -1.7076,   0.7017,  -2.3853,\n",
       "          -0.6180,   1.7212,  -0.5304],\n",
       "        [ -1.5160,  -0.8522,   6.0834,   1.5444,  -0.4422,  -0.5111,   2.9253,\n",
       "          -2.7468,  -0.4352,  -4.0528],\n",
       "        [ -5.8462,  -9.4287,  -4.8359,  -0.6273,  12.2641,   2.3910,  -3.7014,\n",
       "          -0.1377,   4.4309,   7.4246],\n",
       "        [ -2.2455,  -7.5910,   0.9428,  -2.7095,   8.6841,  -2.4710,   0.8592,\n",
       "           1.1190,   0.6655,   4.1451],\n",
       "        [  3.1034,  -4.9626,   1.9520,  -0.1139,  -0.7436,   3.1560,   8.4703,\n",
       "          -5.7513,  -0.7838,  -3.5098],\n",
       "        [ -0.9739,  -3.9761,   1.5265,   9.8107,  -4.8823,   2.9645,  -3.3897,\n",
       "          -1.3004,   0.8239,  -0.4139],\n",
       "        [  1.9205,  -5.0382,  -2.1435,  -0.8310,   1.4773,   5.6020,  -0.6468,\n",
       "          -1.2721,   0.2856,   0.8279],\n",
       "        [ -0.8031,  -2.2156,  -2.1514,   1.9748,   0.2748,   5.1383,  -1.3527,\n",
       "          -2.5653,   1.8302,  -0.1428],\n",
       "        [ -1.2977,  -2.2989,   5.2053,  -1.7203,   0.3239,  -0.8850,   8.7860,\n",
       "          -5.3264,   2.6770,  -4.5350],\n",
       "        [  9.6215, -10.3088,   1.6486,   0.1778,  -4.5711,   4.7196,  -1.0509,\n",
       "          -3.5561,   3.6177,   0.6260],\n",
       "        [ -2.3336,  -8.8571,  -0.5816,  -2.4728,  10.1170,   0.8639,   1.2182,\n",
       "          -0.7843,   1.4234,   2.8010],\n",
       "        [ -5.7048,   6.1407,   0.9879,   1.3192,  -2.4223,  -0.9250,  -2.1366,\n",
       "           1.7702,   0.8956,  -0.3032],\n",
       "        [ -1.3375,  -8.3556,  -1.4134,  -1.2497,   4.1368,  -0.7079,  -3.7732,\n",
       "           4.5146,   1.0306,   8.5039],\n",
       "        [  1.5766,  -1.8685,  -1.5245,  -1.3660,  -0.2558,   4.6908,  -2.4535,\n",
       "           1.5700,   0.6315,  -1.0513],\n",
       "        [ -3.0580,  -2.9478,   0.3527,   5.5671,  -3.5701,   0.3125,  -8.1295,\n",
       "          10.3039,  -1.7686,   3.1162],\n",
       "        [  1.1373,  -5.7013,   5.0199,  -1.5668,  -2.5661,   1.7793,  -0.1977,\n",
       "          -5.6105,   8.1027,   0.7808],\n",
       "        [ -3.3127,  -3.5635,  -0.6427,  -1.2761,   3.6304,   1.3434,  -0.9401,\n",
       "           0.2307,   1.0837,   4.0409],\n",
       "        [ -2.3288,  -0.9156,   5.3555,   6.4224,  -3.3616,  -0.1988,  -2.8435,\n",
       "          -3.8973,   2.9023,  -1.1144]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T12:12:30.793136300Z",
     "start_time": "2026-01-27T12:12:30.761403900Z"
    }
   },
   "cell_type": "code",
   "source": "loss_fn(preds[0].to(device), y[0].to(device))",
   "id": "1a613bd251da674c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-27T12:12:33.032997900Z",
     "start_time": "2026-01-27T12:12:32.976790200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save (inside your training notebook)\n",
    "torch.save(model.state_dict(), \"../weights/mnist_model.pth\")\n",
    "print(\"Saved PyTorch Model State to mnist_model.pth\")"
   ],
   "id": "ade3e47b0b7f6a9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to mnist_model.pth\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
